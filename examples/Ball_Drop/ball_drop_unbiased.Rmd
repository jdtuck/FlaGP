---
title: "Ball Drop Example, No Bias"
author: "Grant Hutchings"
date: "2/23/2022"
output: pdf_document
---

In this example we consider the experiment of dropping balls of varying radii from a tower and recording the time at certain distances during the fall. We will generate time data at distance $d$ from the equation $$
t(d) = \frac{acosh(\exp\{Cd/R\})}{\sqrt{Cg/R}}
$$ where $C$ is the coefficient of drag, $R$ is the radius of the ball, and $g$ is the gravitational constant. Inputs $C,g$ are considered unknown for the noisy observations and are calibration inputs. The computer simulations are evaluated over a space filling design of $(R,C,g)$ tuples in the domain $R\in(.1,2)\times C\in(.01,.5)\times g\in(8,12)$.

This tutorial details unbiased calibration and prediction using library functions.

```{r , echo=FALSE}
C_true = .24
g_true = 9.8
sd_true = .1
t_at_d = function(C,d,R,g){
  (acosh(exp(C*d/R)))/(sqrt(C*g/R))
}

# number of controllable inputs
p.x = 1
# number of calibration inputs
p.t = 2
# number of observations
n = 10
# number of simulations
m = 10082

# generate simulation data
set.seed(11)
XT.sim = lhs::create_oalhs(m,p.t+p.x,T,F)
X.range = c(.1,2) # radius of ball in m
T.range = matrix(c(.01,.5,8,12),nrow=p.t,ncol=2,byrow = T)
X.sim=as.matrix(XT.sim[,1]); X.sim = X.sim * (X.range[2]-X.range[1]) + X.range[1]
T.sim=as.matrix(XT.sim[,2:3])
T.sim[,1] = T.sim[,1] * (T.range[1,2]-T.range[1,1]) + T.range[1,1]
T.sim[,2] = T.sim[,2] * (T.range[2,2]-T.range[2,1]) + T.range[2,1]
rm(XT.sim)
y.ind.sim = as.matrix(seq(1,25,1))
Y.sim = matrix(nrow=length(y.ind.sim),ncol=m)
for(i in 1:m){
  Y.sim[,i] = t_at_d(C=T.sim[i,1],d=y.ind.sim,R=X.sim[i],g=T.sim[i,2])
}
# generate noisy observation data
X.obs = as.matrix(rep(seq(.25,1.75,length.out=n)))
T.obs = matrix(c(rep(C_true,n),rep(g_true,n)),nrow=n,ncol=2)
y.ind.obs = as.matrix(seq(4,20,5))
Y.obs = matrix(nrow=length(y.ind.obs),ncol=n)
for(i in 1:n){
    Y.obs[,i] = t_at_d(C=C_true,d=y.ind.obs,R=X.obs[i],g=g_true) + rnorm(length(y.ind.obs),0,sd_true)
}
```

```{r build FlaGP data object}
flagp.data = flagp(X.sim,T.sim,X.obs,T.obs,Y.sim,y.ind.sim,Y.obs,y.ind.obs,n.pc = 3,
                   ls.subsample = 'blhs', ls.m = 10,ls.K = 3)
```

```{r plot data}
plot(flagp.data,xlab='time (s)',ylab='distance (m)')
```

# Calibrate C,g

```{r mcmc, echo=F}
flagp.mcmc = mcmc(flagp.data, n.samples=5000, n.burn = 1000, end.eta = 50)
```

# Plot MCMC results for diagnostics

```{r plot mcmc, echo=F}
plot(flagp.mcmc,labels=c("C","g"),xlim=c(0,1))
```

Fast MAP estimation

```{r fast point estimate, echo=F}
flagp.map = map(flagp.data,n.restarts = 10,end.eta = 50)
flagp.map$theta.hat
```

# Prediction at observed locations

We now show how to predict from our emulator at new input settings.

Prediction using MCMC is done with the function `ypred_mcmc()`. We specify that we would like to predict on the full support of heights from $1m$ to $25m$ by setting $\texttt{support='sim'}$. $\texttt{support='obs'}$ will return predictions only at the points $\texttt{y.ind.obs}$.

```{r, echo=F}
X.pred = matrix(seq(X.obs[1]-.1,X.obs[n]+.1,length.out=5))
flagp.pred.mcmc = predict(flagp.data,flagp.mcmc,
                           X.pred.orig=X.pred,
                           samp.ids = as.integer(seq(1,4000,length.out=250)),
                           support = "sim",
                           return.samples = T, conf.int = T)
flagp.pred.map = predict(flagp.data,flagp.map,
                         X.pred.orig=X.pred,
                         n.samples=1000,
                         support = "sim",
                         return.samples = T,conf.int = T)
```

```{r, compare predictions to data}
Y.pred = matrix(nrow=length(y.ind.sim),ncol=nrow(X.pred))
for(i in 1:ncol(Y.pred)){
  Y.pred[,i] = t_at_d(C_true,y.ind.sim,X.pred[i],g_true)
}

matplot(flagp.pred.map$y.mean,type='l',lty=2,main='MAP')
matplot(Y.pred,type='l',lty=1,add=T)
matplot(flagp.pred.map$y.conf.int[1,,],type='l',lty=3,add=T)
matplot(flagp.pred.map$y.conf.int[2,,],type='l',lty=3,add=T)

matplot(flagp.pred.mcmc$y.mean,type='l',lty=2,main='MCMC')
matplot(Y.pred,type='l',lty=1,add=T)
matplot(flagp.pred.mcmc$y.conf.int[1,,],type='l',lty=3,add=T)
matplot(flagp.pred.mcmc$y.conf.int[2,,],type='l',lty=3,add=T)

# RMSE
rmse.mcmc = sqrt(colMeans((flagp.pred.mcmc$y.mean-Y.pred)^2))
rmse.map = sqrt(colMeans((flagp.pred.map$y.mean-Y.pred)^2))

# Interval Score
is.mcmc = colMeans(FlaGP:::interval_score(Y.pred,y.conf=flagp.pred.mcmc$y.conf.int))
is.map = colMeans(FlaGP:::interval_score(Y.pred,y.conf=flagp.pred.map$y.conf.int))

cat('mcmc prediction scores:\nrmse:',rmse.mcmc,'\ninterval score:',is.mcmc,'\n')
cat('map prediction scores:\nrmse:',rmse.map,'\ninterval score:',is.map,'\n')
```
